{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump\n",
    "import mysql.connector\n",
    "import pandas as pd\n",
    "#import dask.dataframe as dd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import missingno as msno\n",
    "from time import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx = mysql.connector.connect(user='****', password='****', host='127.0.0.1', database='urls')\n",
    "cursor = cnx.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'urls'\")\n",
    "tables_list = [tables[0] for tables in cursor.fetchall()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tables = list(filter(lambda x: \"token\" in x, tables_list))\n",
    "data_tables = list(filter(lambda x: \"table\" in x, tables_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = []\n",
    "for i in data_tables:\n",
    "    query = \"SELECT * FROM %s\"%(i)\n",
    "    tables.append(pd.read_sql_query(query, con=cnx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = []\n",
    "for i in tokens_tables:\n",
    "    query = \"SELECT * FROM %s\"%(i)\n",
    "    tokens.append(pd.read_sql_query(query, con=cnx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnx.commit()\n",
    "cursor.close()\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat all tokens db in one\n",
    "num_urls = sum([token.shape[0] for token in tokens])\n",
    "db_tokens = pd.concat(tokens, sort=False, ignore_index=True)\n",
    "db_tokens.drop_duplicates(subset=[\"url\"], inplace=True)\n",
    "print(\"Size of complete tokens database: \", db_tokens.shape)\n",
    "print(\"Num of URLS should be: \", num_urls)\n",
    "assert(num_urls == db_tokens.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"condition  = db_tokens['url'].duplicated()\n",
    "print(db_tokens.index[condition])\n",
    "print(db_tokens.iloc[2085][\"url\"])\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Concat all table db in one\n",
    "num_urls = sum([table.shape[0] for table in tables])\n",
    "db_tables = pd.concat(tables, sort=False, ignore_index=True)\n",
    "db_tables.drop_duplicates(subset=[\"url\"], inplace=True)\n",
    "print(\"Size of complete tables database: \", db_tables.shape)\n",
    "print(\"Num of URLS should be: \", num_urls)\n",
    "assert(num_urls == db_tables.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Delete tokens urls that don't appear on table\n",
    "url_list = list(db_tables[\"url\"])\n",
    "condition  = ~db_tokens['url'].isin(url_list)\n",
    "delete_list = db_tokens.index[condition]\n",
    "db_tokens.drop(delete_list, inplace=True)\n",
    "db_tokens.reset_index(drop=True, inplace=True)\n",
    "\n",
    "#Delete table urls that don't appear on tokens\n",
    "url_list = list(db_tokens[\"url\"])\n",
    "condition  = ~db_tables['url'].isin(url_list)\n",
    "delete_list = db_tables.index[condition]\n",
    "db_tables.drop(delete_list, inplace=True)\n",
    "db_tables.reset_index(drop=True, inplace=True)\n",
    "\n",
    "assert (db_tokens.shape[0]==db_tables.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If some error in the tokens db correct it\n",
    "\"\"\"from FeatureExtraction import *\n",
    "from SQL_Manager import *\n",
    "\n",
    "\n",
    "url_list = list(db_tokens[\"url\"])\n",
    "condition  = ~db_tables['url'].isin(url_list)\n",
    "delete_list = db_tables.index[condition]\n",
    "tokens_table = \"Tokens7\"\n",
    "for ind in (delete_list):\n",
    "    \n",
    "    url = db_tables.iloc[ind][\"url\"]\n",
    "    malicious = db_tables.iloc[ind][\"malicious\"].item()\n",
    "    tokens_dict={}\n",
    "    tokens_dict[\"url\"] = url\n",
    "    tokens_dict[\"malicious\"] = malicious\n",
    "    lexical_dict, t_dict = get_lexicalf(url)\n",
    "    #t_dict.astype(int)\n",
    "    tokens_dict.update(t_dict)\n",
    "    print(type(db_tables.iloc[ind][\"malicious\"]))\n",
    "    print(tokens_dict)\n",
    "\n",
    "    tres = make_insertion(tokens_dict, tokens_table)\n",
    "    if tres==1:\n",
    "        tokens_table = tokens_table[:6]+str(int(tokens_table[6])+1)\n",
    "        create_table(tokens_table)\n",
    "        tres = make_insertion(tokens_dict, tokens_table)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tables.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manage NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#msno.matrix(db_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that only have nulls in tokens\n",
    "prev_col = db_tokens.shape[1]\n",
    "db_tokens.dropna(how=\"all\", axis=1, inplace=True)\n",
    "print(\"Deleted columns: \", prev_col - db_tokens.shape[1])\n",
    "# In tokens databases fill of 0\n",
    "db_tokens.fillna(0, inplace=True)\n",
    "print(\"Tokens databse filled with 0s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop columns that only have nulls in tables\n",
    "prev_col = db_tables.shape[1]\n",
    "db_tables.dropna(how=\"all\", axis=1, inplace=True)\n",
    "print(\"Deleted columns: \", prev_col - db_tables.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(db_tables.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Solve dtypes errors\n",
    "def replace_OS(x):\n",
    "    if(type(x) == str): x = x.split(\"/\")[0]\n",
    "    return x\n",
    "db_tables[\"h_contlen\"] = db_tables[\"h_contlen\"].apply(pd.to_numeric)\n",
    "db_tables[\"h_lastmod\"] = db_tables[\"h_lastmod\"].apply(pd.to_datetime, errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "db_tables[\"server_OS\"] = db_tables[\"server_OS\"].apply(lambda x: replace_OS(x))\n",
    "print(db_tables.dtypes.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_cols = []\n",
    "date_cols = []\n",
    "numeric_cols = {}\n",
    "for col in db_tables.columns:\n",
    "    if db_tables[col].dtype == \"object\":            #object, datetime64[ns], float64, int64\n",
    "        str_cols.append(col)\n",
    "    if db_tables[col].dtype == \"datetime64[ns]\":\n",
    "        date_cols.append(col)\n",
    "    if db_tables[col].dtype in (\"float64\", \"int64\"):\n",
    "        numeric_cols[col]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numeric columns are filled with 0s\n",
    "print(\"Numeric null before: \", db_tables[numeric_cols.keys()].isna().sum().sum())\n",
    "db_tables.fillna(value=numeric_cols, inplace=True)\n",
    "print(\"Numeric null after: \", db_tables[numeric_cols.keys()].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_cols = []\n",
    "for col in numeric_cols:\n",
    "    if \"freq_\" in col:\n",
    "        freq_cols.append(col)\n",
    "    \n",
    "for col in freq_cols:\n",
    "    db_tables[col] = round(db_tables[col]/db_tables[\"len_url\"],3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in (str_cols):\n",
    "    if col in ['full_text', 'domain','path', 'complete_path', 'host_country', 'query', 'url', 'subdomain', 'final_url', 'netloc', 'scheme']:\n",
    "        continue\n",
    "    if col in list(filter(lambda x: \"IP\" in x, str_cols)):\n",
    "        continue\n",
    "    if col in list(filter(lambda x: \"PTR\" in x, str_cols)):\n",
    "        continue\n",
    "    print(col, db_tables[col].nunique())\n",
    "print(\"Feature;\")\n",
    "#print(db_tables[\"server_OS\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#String columns\n",
    "print(\"String null before: \", db_tables[str_cols].isna().sum().sum())\n",
    "print(\"Shape before: \", db_tables.shape)\n",
    "\n",
    "# Columns to encode\n",
    "encoding_cols = [c for c in str_cols if c not in list(filter(lambda x: \"IP\" in x, str_cols))]\n",
    "encoding_cols = [c for c in encoding_cols if c not in list(filter(lambda x: \"PTR\" in x, str_cols))]\n",
    "encoding_cols = [c for c in encoding_cols if c not in ['full_text', 'domain','path', 'complete_path', 'host_country', 'query','subdomain', 'final_url', 'netloc', 'scheme']]\n",
    "prefixes = {}\n",
    "for c in encoding_cols:\n",
    "    if c==\"url\":\n",
    "        continue\n",
    "    if \"PTR\" in c:\n",
    "        prefixes[c] = \"PTR\"\n",
    "    else:\n",
    "        prefixes[c] = c\n",
    "\n",
    "# Columns to drop\n",
    "delete_columns = [c for c in str_cols if c not in encoding_cols]\n",
    "db_tables.drop(columns=delete_columns, inplace=True)\n",
    "\n",
    "#One Hot encoding\n",
    "encoding_cols = [c for c in encoding_cols if c != \"url\"]\n",
    "db_tables = pd.get_dummies(db_tables, prefix=prefixes, columns=encoding_cols, drop_first=False)\n",
    "\n",
    "print(\"Shape after: \", db_tables.shape)\n",
    "print(\"String null after: \", db_tables.isna().sum().sum() - db_tables[date_cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Date columns\n",
    "print(\"Date null before: \", db_tables[date_cols].isna().sum().sum())\n",
    "df = pd.DataFrame()\n",
    "new_date_cols ={}\n",
    "for col in date_cols:\n",
    "    df[col+\"_year\"] = db_tables[col].dt.year\n",
    "    new_date_cols[col+\"_year\"] = 3000\n",
    "    df[col+\"_month\"] = db_tables[col].dt.month\n",
    "    new_date_cols[col+\"_month\"] = 20\n",
    "    df[col+\"_week\"]= db_tables[col].dt.isocalendar()[\"week\"]\n",
    "    new_date_cols[col+\"_week\"] = 60\n",
    "    df[col+\"_day\"] = db_tables[col].dt.day\n",
    "    new_date_cols[col+\"_day\"] = 40\n",
    "    df[col+\"_hour\"] = db_tables[col].dt.hour\n",
    "    new_date_cols[col+\"_hour\"] = 30\n",
    "    df[col+\"_minute\"] = db_tables[col].dt.minute\n",
    "    new_date_cols[col+\"_minute\"] = 70\n",
    "    df[col+\"_dayofweek\"] = db_tables[col].dt.isocalendar()[\"day\"]\n",
    "    new_date_cols[col+\"_dayofweek\"] = 10\n",
    "\n",
    "   \n",
    "df.fillna(value = new_date_cols, inplace=True)\n",
    "db_tables[list(new_date_cols.keys())]=df[list(new_date_cols.keys())]\n",
    "\n",
    "print(\"Date null after: \", db_tables[new_date_cols].isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_tables.drop(columns=date_cols, inplace=True)\n",
    "print(\"Total final null: \", db_tables.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = list(db_tables)\n",
    "cols_list.remove(\"url\")\n",
    "cols_list.remove(\"malicious\")\n",
    "X_table = db_tables[cols_list]   \n",
    "y_table = db_tables[\"malicious\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list = list(db_tokens)\n",
    "cols_list.remove(\"url\")\n",
    "cols_list.remove(\"malicious\")\n",
    "X_tokens = db_tokens[cols_list]    \n",
    "y_tokens = db_tokens[\"malicious\"]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ML classification algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import preprocessing tools\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#Import classifiers\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NeighborhoodComponentsAnalysis\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "\n",
    "#Import feature selection\n",
    "#from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector\n",
    "from mlxtend.plotting import plot_sequential_feature_selection as plot_sfs\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import chi2, f_classif   #f_classif=ANOVA\n",
    "\n",
    "#Import evaluation metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import brier_score_loss\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingGridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.calibration import CalibrationDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Previous dimensionality reduction on tokens\n",
    "skx = SelectKBest(chi2, k=50)      \n",
    "skx_tokens = skx.fit(X_tokens,y_tokens)     #reduce to just 700 more important bag of words tokens\n",
    "token_cols = skx_tokens.get_feature_names_out()\n",
    "token_cols = np.append(token_cols,\"malicious\")\n",
    "token_cols = np.append(token_cols,\"url\")\n",
    "db_tokens_reduce = db_tokens[token_cols]\n",
    "\n",
    "#Create new db\n",
    "join_db = db_tables.merge(db_tokens_reduce, how=\"outer\") #outer\n",
    "print(\"Columns reduction by CHI2: \", (db_tokens.shape[1]+db_tables.shape[1]-2)-(db_tokens_reduce.shape[1]+db_tables.shape[1]-2))\n",
    "print(\"Columns addition: \", db_tokens_reduce.shape[1]+db_tables.shape[1]-2)\n",
    "assert(db_tokens_reduce.shape[1]+db_tables.shape[1]-2 == join_db.shape[1] )\n",
    "print(\"Total final null: \", join_db.isna().sum().sum())\n",
    "print(\"Full Dataset Shape\", join_db.shape)\n",
    "\n",
    "cols_list = list(join_db)\n",
    "cols_list.remove(\"url\")\n",
    "cols_list.remove(\"malicious\")\n",
    "X = join_db[cols_list]    \n",
    "y = join_db[\"malicious\"]  \n",
    "\n",
    "\n",
    "#Filter best features\n",
    " \n",
    "spa = SelectPercentile(f_classif, percentile=60)\n",
    "X= spa.fit_transform(X,y)\n",
    "final_features = spa.get_feature_names_out()\n",
    "print(\"After ANOVA feature select\", X.shape)\n",
    "#Standard Scaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X,y)\n",
    "X = scaler.transform(X)\n",
    "\n",
    "t = time()\n",
    "nca = NeighborhoodComponentsAnalysis(tol=0.001, max_iter=60, n_components=70, random_state=41)\n",
    "X_NCA = nca.fit_transform(X,y)\n",
    "print(\"After NCA space reduction\", X_NCA.shape)\n",
    "print(\"NCA time: \", time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat = spa.feature_names_in_\n",
    "values = spa.pvalues_\n",
    "\n",
    "enumerate_object = enumerate(values)\n",
    "sorted_pairs = sorted(enumerate_object, key=lambda elem: elem[1])\n",
    "\n",
    "sorted_indices = []\n",
    "for index, element in sorted_pairs:\n",
    "    sorted_indices.append(index)\n",
    "\n",
    "feat_dict = defaultdict(list)\n",
    "c=0\n",
    "for i in (sorted_indices):\n",
    "    feat_dict[\"Feature\"].append(spa.feature_names_in_[i])\n",
    "    feat_dict[\"pvalue\"].append(spa.pvalues_[i])\n",
    "    c+=1\n",
    "    \n",
    "    feat_db = pd.DataFrame(feat_dict)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "feat_db.head(20)\n",
    "#feat_db.to_excel('top_features_ANOVA.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()\n",
    "    return {'tn': tn, 'fp': fp,\n",
    "            'fn': fn, 'tp': tp}\n",
    "\n",
    "\n",
    "scoring = {\"accuracy\":make_scorer(accuracy_score),\n",
    "            \"fbeta\":make_scorer(fbeta_score,beta=2), \n",
    "            \"recall\":make_scorer(recall_score) ,\n",
    "            \"precision\":make_scorer(precision_score) ,\n",
    "            \"auroc\":make_scorer(roc_auc_score, needs_proba=True)}\n",
    "\n",
    "def metrics(ground_truth, prediction, predict_proba):\n",
    "    conf_mat = confusion_matrix(ground_truth, prediction, labels=[1,0])\n",
    "    acc = accuracy_score(ground_truth,prediction)\n",
    "    recall = recall_score(ground_truth,prediction)\n",
    "    precision= precision_score(ground_truth,prediction)\n",
    "    fbeta=fbeta_score(ground_truth,prediction,beta=2)\n",
    "    auroc=roc_auc_score(ground_truth, predict_proba[:, 1])\n",
    "    brier = brier_score_loss(ground_truth,predict_proba[:, 1])\n",
    "    logloss = log_loss(ground_truth,predict_proba)\n",
    "    return [(\"Confusion Matrix: \", conf_mat),(\"Accuracy: \", acc), (\"Recall: \", recall),(\"Precision: \", precision), (\"F2-value: \", fbeta), \n",
    "    (\"AUROC: \", auroc), (\"Brier: \", brier), (\"LogLoss: \", logloss)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfSVM_pipe = Pipeline([(\"svc\",SVC())])\n",
    "\n",
    "param_grid = {\"svc__C\": [10, 50, 100, 1000],\n",
    "                \"svc__kernel\":[\"rbf\"],\n",
    "                \"svc__probability\":[True],\n",
    "                \"svc__gamma\":[\"scale\",\"auto\", 1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "              \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=rbfSVM_pipe, param_grid=param_grid, scoring=scoring[\"accuracy\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=\"exhaust\")\n",
    "hgs = hgs.fit(X, y)\n",
    "rbfSVM_pipe.set_params(**hgs.best_params_)\n",
    "\n",
    "\n",
    "rbf_svm_result = cross_validate(rbfSVM_pipe, X, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(rbf_svm_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "\n",
    "print(rbfSVM_pipe)\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbfSVM_pipe = Pipeline([(\"svc\",SVC())])\n",
    "\n",
    "param_grid = {\"svc__C\": [10, 50, 100, 1000],\n",
    "                \"svc__kernel\":[\"rbf\"],\n",
    "                \"svc__probability\":[True],\n",
    "                \"svc__gamma\":[\"scale\",\"auto\", 1, 0.1, 0.01, 0.001, 0.0001]}\n",
    "              \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=rbfSVM_pipe, param_grid=param_grid, scoring=scoring[\"accuracy\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=\"exhaust\")\n",
    "hgs = hgs.fit(X_NCA, y)\n",
    "rbfSVM_pipe.set_params(**hgs.best_params_)\n",
    "\n",
    "rbf_svm_result = cross_validate(rbfSVM_pipe, X_NCA, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(rbf_svm_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(rbfSVM_pipe)\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lSVM_pipe = Pipeline([(\"svc\",SVC())])\n",
    "#lSVM_pipe = Pipeline([(\"svc\",LinearSVC())])\n",
    "\n",
    "param_grid = {\"svc__C\": [10, 50, 100, 1000],\n",
    "                \"svc__kernel\":[\"linear\"],\n",
    "                \"svc__probability\":[True]}\n",
    "\n",
    "\"\"\"param_grid = {\"svc__C\": [100, 1000],\n",
    "                \"svc__max_iter\":range(1000,3000,100)}\"\"\"\n",
    "               \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=lSVM_pipe, param_grid=param_grid, scoring=scoring[\"accuracy\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=500)\n",
    "hgs = hgs.fit(X_NCA, y)\n",
    "lSVM_pipe.set_params(**hgs.best_params_)\n",
    "\n",
    "\"\"\"scoring_linear = {\"accuracy\":make_scorer(accuracy_score),\n",
    "           \"fbeta\":make_scorer(fbeta_score,beta=2), \n",
    "            \"recall\":make_scorer(recall_score) ,\n",
    "            \"precision\":make_scorer(precision_score)}\"\"\"\n",
    "\n",
    "print(\"Best params for linearSVM:\", hgs.best_params_)\n",
    "linear_svm_result = cross_validate(lSVM_pipe, X_NCA, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(linear_svm_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(lSVM_pipe)\n",
    "results.head(8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtpipe = Pipeline([(\"dt\", DecisionTreeClassifier())])\n",
    "\n",
    "param_grid = {\"dt__criterion\": [\"gini\"],\n",
    "                \"dt__max_depth\": range(30,100,5),\n",
    "                \"dt__min_impurity_decrease\":[0.1, 0.5 ,0.05],\n",
    "                \"dt__min_samples_split\":range(2,30,2)}\n",
    "               \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=dtpipe, param_grid=param_grid, scoring=scoring[\"fbeta\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=300)\n",
    "hgs = hgs.fit(X, y)\n",
    "dtpipe.set_params(**hgs.best_params_)\n",
    "\n",
    "print(\"Best params for rbfSVM:\", hgs.best_params_)\n",
    "dt_result = cross_validate(dtpipe, X, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(dt_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(dtpipe)\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pipe = Pipeline([(\"knn\",KNeighborsClassifier())])\n",
    "param_grid = {\"knn__n_neighbors\": range(5,50,1),\n",
    "                \"knn__weights\":[\"uniform\"]}\n",
    "               \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=knn_pipe, param_grid=param_grid, scoring=scoring[\"accuracy\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=300)\n",
    "hgs = hgs.fit(X, y)\n",
    "knn_pipe.set_params(**hgs.best_params_)\n",
    "\n",
    "print(\"Best params for rbfSVM:\", hgs.best_params_)\n",
    "knn_result = cross_validate(knn_pipe, X, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(knn_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(knn_pipe)\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#knn_pipe_nca = Pipeline([(\"scaler\",scaler), (\"nca\", nca), (\"knn\",KNeighborsClassifier())])\n",
    "knn_pipe_nca = Pipeline([(\"knn\",KNeighborsClassifier())])\n",
    "\n",
    "param_grid = {\"knn__n_neighbors\": range(5,50,1),\n",
    "                \"knn__weights\":[\"uniform\",\"distance\"]}\n",
    "               \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=knn_pipe_nca, param_grid=param_grid, scoring=scoring[\"fbeta\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=300)\n",
    "hgs = hgs.fit(X_NCA, y)\n",
    "knn_pipe_nca.set_params(**hgs.best_params_)\n",
    "\n",
    "print(\"Best params for rbfSVM:\", hgs.best_params_)\n",
    "knn_nca_result = cross_validate(knn_pipe_nca, X_NCA, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(knn_nca_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(knn_pipe_nca)\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ensamble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit best estimators on all the data\n",
    "clf_list = [(\"rbfSVM\", rbfSVM_pipe),\n",
    "            (\"Decision Tree\", dtpipe),\n",
    "            (\"kNN\", knn_pipe_nca)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagg_pipe = Pipeline([(\"bgg\",BaggingClassifier(base_estimator=SVC(),n_jobs=-1, random_state=40))])\n",
    "\n",
    "param_grid = {\"bgg__n_estimators\": range(10,30,5),\n",
    "                \"bgg__max_samples\":[p/10 for p in range(2, 10,2)],\n",
    "                \"bgg__max_features\":[p/10 for p in range(2, 10,2)]}\n",
    "               \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=bagg_pipe, param_grid=param_grid, scoring=scoring[\"fbeta\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=300)\n",
    "hgs = hgs.fit(X_NCA, y)\n",
    "bagg_pipe.set_params(**hgs.best_params_)\n",
    "\n",
    "bagg_result = cross_validate(bagg_pipe, X_NCA, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(bagg_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(bagg_pipe)\n",
    "clf_list.append((\"Bagging\", bagg_pipe))\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfpipe = Pipeline([(\"rf\",RandomForestClassifier(n_estimators= 100, max_features=\"sqrt\", random_state=40))])\n",
    "\n",
    "param_grid = {\"rf__n_estimators\": range(90,100,1),\n",
    "                \"rf__max_features\": ['sqrt', 'log2',None]}\n",
    "               \n",
    "\n",
    "#hgs = HalvingGridSearchCV(estimator=rfpipe, param_grid=param_grid, scoring=scoring[\"accuracy\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=200)\n",
    "#hgs = hgs.fit(X, y)\n",
    "#rfpipe.set_params(**hgs.best_params_)\n",
    "\n",
    "rf_result = cross_validate(rfpipe, X, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(rf_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(rfpipe)\n",
    "clf_list.append((\"Random Forest\", rfpipe))\n",
    "results.head(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_pipe = Pipeline([(\"ada\",AdaBoostClassifier(random_state=40))])\n",
    "\n",
    "param_grid = {\"ada__n_estimators\": range(50,100,10),\n",
    "            \"ada__learning_rate\": [0.1,0.5,1,3,5,10]}\n",
    "               \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=ada_pipe, param_grid=param_grid, scoring=scoring[\"accuracy\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=300)\n",
    "hgs = hgs.fit(X, y)\n",
    "ada_pipe.set_params(**hgs.best_params_)\n",
    "\n",
    "ada_result = cross_validate(ada_pipe, X, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(ada_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(ada_pipe)\n",
    "clf_list.append((\"AdaBoost\", ada_pipe))\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pipe = Pipeline([(\"xgb\",XGBClassifier(random_state=40))])\n",
    "\n",
    "param_grid = {\"xgb__n_estimators\": range(50,100,10),\n",
    "            \"xgb__learning_rate\": [0.1,0.5,1,3,5,10]}\n",
    "               \n",
    "\n",
    "hgs = HalvingGridSearchCV(estimator=xgb_pipe, param_grid=param_grid, scoring=scoring[\"accuracy\"], factor=3, n_jobs=-1 , refit=False, cv=3, verbose=4, min_resources=300)\n",
    "hgs = hgs.fit(X, y)\n",
    "xgb_pipe.set_params(**hgs.best_params_)\n",
    "\n",
    "ada_result = cross_validate(xgb_pipe, X, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "results = pd.DataFrame(ada_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "\n",
    "print(xgb_pipe)\n",
    "clf_list.append((\"XGBoost\", xgb_pipe))\n",
    "results.head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_NCA, y, test_size=0.30, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators=clf_list, weights=[4,2,2,4,1,2,1], voting=\"soft\")\n",
    "\n",
    "vc = vc.fit(X_train, y_train)\n",
    "print(metrics(y_test,vc.predict(X_test), vc.predict_proba(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = VotingClassifier(estimators=clf_list, weights=[4,1,1,4,3,1,1], voting=\"soft\")\n",
    "vc_result = cross_validate(vc, X_NCA, y, cv=6, scoring=scoring, verbose=4)\n",
    "results = pd.DataFrame(vc_result)\n",
    "results.loc['mean'] = results.mean()\n",
    "results.loc['std'] = results.std()\n",
    "results.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Probability calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_clf_list = []\n",
    "for (name,clf) in clf_list:\n",
    "    #Platt\n",
    "    platt = CalibratedClassifierCV(clf, method=\"sigmoid\", cv=6, n_jobs=-1)\n",
    "    prob_clf_list.append((name+\"+ Platt\",platt))\n",
    "    iso = CalibratedClassifierCV(clf, method=\"isotonic\", cv=6, n_jobs=-1)\n",
    "    prob_clf_list.append((name+\"+ Isotonic\",iso))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "scores = defaultdict(list)\n",
    "for i, (name, clf) in enumerate(prob_clf_list):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    prob_yhat = clf.predict_proba(X_test)\n",
    "    yhat = clf.predict(X_test)\n",
    "    scores[\"Classifier\"].append(name)\n",
    "    \n",
    "    values = metrics(y_test, yhat, prob_yhat)\n",
    "\n",
    "    for (metric,value) in values:\n",
    "        scores[metric].append(value)\n",
    "\n",
    "    score_df = pd.DataFrame(scores).set_index(\"Classifier\")\n",
    "    score_df.round(decimals=5)\n",
    "\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = {\"accuracy\":make_scorer(accuracy_score),\n",
    "            \"fbeta\":make_scorer(fbeta_score,beta=2), \n",
    "            \"recall\":make_scorer(recall_score) ,\n",
    "            \"precision\":make_scorer(precision_score) ,\n",
    "            \"auroc\":make_scorer(roc_auc_score, needs_proba=True),\n",
    "            \"brier\":make_scorer(brier_score_loss, greater_is_better=False, needs_proba=True),\n",
    "            \"log_loss\":make_scorer(log_loss, greater_is_better=False, needs_proba=True)}\n",
    "\n",
    "scores = defaultdict(list)\n",
    "for i, (name, clf) in enumerate(prob_clf_list):\n",
    "    \n",
    "    res = cross_validate(clf, X_NCA, y, cv=6, scoring=scoring, n_jobs=-1, verbose=4)\n",
    "    results = pd.DataFrame(res)\n",
    "    cols = list(results)\n",
    "    \n",
    "    scores[\"Classifier\"].append(name)\n",
    "    for (c,mean) in enumerate(results.mean()):\n",
    "        scores[cols[c]].append(mean)\n",
    "\n",
    "    score_df = pd.DataFrame(scores).set_index(\"Classifier\")\n",
    "    score_df.round(decimals=5)\n",
    "\n",
    "score_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results plot and graphical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot calibration curves\n",
    "alg_list = [prob_clf_list[a] for a in range(0,len(prob_clf_list),2)]\n",
    "for j, (algorithm,x) in enumerate(alg_list):\n",
    "    \n",
    "    f=j*2\n",
    "    s=f+2\n",
    "    fig = plt.figure(figsize=(20, 20))\n",
    "    colors = plt.cm.get_cmap(\"Dark2\")\n",
    "    ax = fig.add_subplot()\n",
    "\n",
    "    calibration_displays = {}\n",
    "    for i, (name, clf) in enumerate(prob_clf_list[f:s]):\n",
    "        clf.fit(X_train, y_train)\n",
    "        display = CalibrationDisplay.from_estimator(\n",
    "            clf,\n",
    "            X_test,\n",
    "            y_test,\n",
    "            n_bins=5,\n",
    "            name=name,\n",
    "            ax=ax,\n",
    "            color=colors(i),\n",
    "        )\n",
    "        calibration_displays[name] = display\n",
    "\n",
    "    plt.title(\"Calibration Curves (%s)\"%(algorithm.split(\"+\")[0]))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "tsne_results = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X)\n",
    "\n",
    "x_tsne = tsne_results[:,0]\n",
    "y_tsne = tsne_results[:,1]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=x_tsne, y=y_tsne,\n",
    "    hue=y,\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "tsne_results = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X_NCA)\n",
    "\n",
    "x_tsne = tsne_results[:,0]\n",
    "y_tsne = tsne_results[:,1]\n",
    "\n",
    "sns.scatterplot(\n",
    "    x=x_tsne, y=y_tsne,\n",
    "    hue=y,\n",
    "    palette=sns.color_palette(\"hls\", 2),\n",
    "    legend=\"full\",\n",
    "    alpha=0.3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dump(final_features, open('model_columns', 'wb'))      #Save columns\n",
    "#dump(clf, open('model.pkl', 'wb'))      #Save model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8571e7f3e92f6e490cddd84ef78d4e4e0b96a1f565959148b10a39523fba88f5"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
